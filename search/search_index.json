{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NextITS","text":"<p>NextITS is an automated pipeline for metabarcoding fungi and other eukaryotes with full-length ITS sequenced with PacBio.</p>"},{"location":"#introduction","title":"Introduction","text":"<p>The most widely used genetic markers for metabarcoding fungal communities are highly variable rRNA ITS1 and ITS2 sub-regions of the internal transcribed spacer. High-throughput metabarcoding has greatly improved our understanding of fungal community ecology. Here, we present NextITS, an automated pipeline for analyzing full-length ITS sequences (ITS1-5.8S-ITS2) from the Pacific Biosciences (PacBio) third-generation sequencing platform. Although the PacBio HiFi reads are highly accurate, the primary type of sequencing error is insertions or deletions in homopolymeric sites, which are also naturally common in fungal ITS. In the pipeline, we implemented correction of homopolymer errors, detection of tag-switching artifacts, and recovery of sequences false-positively annotated as chimeric. The pipeline is built using Nextflow workflow manager, with all the software dependencies packaged into Docker and Singularity containers.</p>"},{"location":"#nextits-workflow","title":"NextITS Workflow","text":""},{"location":"#citation","title":"Citation","text":"<p>Mikryukov V., Anslan S., Tedersoo L. NextITS: a pipeline for metabarcoding fungi and other eukaryotes with full-length ITS sequenced with PacBio. https://github.com/vmikk/NextITS</p>"},{"location":"HPC/","title":"Usage on HPC cluster","text":"<p>NextITS leverages the capabilities of the Nextflow workflow manager,  designed to maximize the efficiency and flexibility of your analyses by fully utilizing available computational resources.  This means that you can seamlessly deploy the pipeline on high-performance computing (HPC) clusters,  making it especially beneficial for large-scale datasets.  </p> <p>Nextflow is compatible with all major job schedulers, including  Slurm,  OpenPBS,  TORQUE,  and Apache Ignite,  to name a few.  In the upcoming section, we'll guide you through the process of setting up and initiating NextITS on a cluster environment,  like your University's computing cluster.  </p> <p>Tips for optimizing pipeline performance on HPC clusters</p> <p>For an in-depth exploration, including details on specific workload manager features, please refer to https://www.nextflow.io/blog/2023/best-practices-deploying-pipelines-with-hpc-workload-managers.html.  </p>"},{"location":"HPC/#usage-scenarios","title":"Usage scenarios","text":"<p>Three potential usage scenarios are:  </p> <ul> <li> <p>Simple Mode:     This scenario involves a single, self-contained job.      Here, Nextflow initiates all tasks on the same computing node it operates on.      The total amount of requested resources is cumulatively allocated to all tasks.  </p> </li> <li> <p>Cluster Mode:     In this scenario, Nextflow operates on a computing node, using a long-duration task with low resource allocation.      From this node, it begins dispatching separate jobs (e.g., using Slurm).      It's important to configure individual resource requirements for each job in this scenario, as they are autonomous of each other.      This mode is ideal for handling extensive datasets.      However, the turnaround time might increase based on the cluster's activity, since each task might have to wait its turn in the queue.      Despite this, the mode offers heightened flexibility because it allows for precise resource allocation and scaling based on the demands of individual tasks.     For a clearer understanding of this scenario, consider the following illustration:      (Image source: https://www.nextflow.io/blog/2023/best-practices-deploying-pipelines-with-hpc-workload-managers.html).  </p> </li> <li> <p>Hybrid Workload:     This versatile scenario integrates various resources (local/HPC/cloud).      Specific tasks, depending on their requirements, might be delegated to another infrastructure boasting superior hardware.      For instance, a sequence clustering task might be resource-intensive but can efficiently use multiple CPUs.      Such a task can be dispatched to a cloud service (e.g., AWS Batch), and once processed,      the results can be retrieved and the pipeline can continue executing other tasks using the primary executor.      This approach taps into the best of both worlds by using specialized resources for demanding tasks and local or primary resources for regular tasks.  </p> </li> </ul> <p>In this guide, we'll concentrate on the simple scenario,  ideal for managing medium-to-large-sized datasets and aligning with the needs of most users.  We'll primarily focus on configurations and commands tailored for Slurm,  given its popularity in academic institutions.  If you're uncertain about the workload manager employed on your HPC, please reach out to your IT department.  </p>"},{"location":"HPC/#resource-requirements","title":"Resource requirements","text":"<p>When initiating a job on a cluster, consider specifying these resource requirements:</p> <ul> <li>CPUs: The required number of processor cores for the task.  </li> <li>Memory: Different processes might have distinct RAM needs. For instance, sequence clustering often demands more memory.  </li> <li>Time: The maximum duration allowed for the pipeline to run.  </li> </ul> <p>The HPC scheduler utilizes these details to allocate your task to a suitable computing node.  Determining the right resources often varies based on the dataset's size.  Additionally, your system may have some restrictions based on its HPC policies.  Overallocating can lead to underutilized resources, longer wait times, and reduced cluster efficiency for other users.  Conversely, underallocating risks task failures.</p>"},{"location":"installation/","title":"Installation","text":"<p>NextITS was primarily developed for Linux. To run it from a command line on Windows, please use Windows Subsystem for Linux (WSL).</p> <p>All pipeline dependencies were encapsulated in Singularity and Docker containers,  which will be automatically downloaded with the first run of NextITS.  Only the main dependencies must be installed manually. They include:  </p> <ul> <li>Java </li> <li>Nextflow </li> <li>Singularity or Docker container engine</li> </ul>"},{"location":"installation/#nextflow","title":"Nextflow","text":"<p>Nextflow is the workflow manager responsible for  coordinating and executing all command line tools seamlessly. </p>"},{"location":"installation/#manual-installation","title":"Manual installation","text":"<p><code>Nextflow</code> (<code>&gt;=23.04.0</code>)  requires Java 11 (or later, up to 20) to be installed.</p> <p>To install Java, you may use your system's package manager. If you're using Debian/Ubuntu, execute the following command: <pre><code>sudo apt-get update\nsudo apt-get install default-jdk\n</code></pre></p> <p>Alternatively, you may install Java using SDKMAN!: <pre><code>curl -s \"https://get.sdkman.io\" | bash\nsdk install java 17.0.6-amzn\n</code></pre></p> <p>Then, install Nextflow:</p> <pre><code>wget -qO- https://get.nextflow.io | bash\nchmod +x ./nextflow\nmkdir -p ~/bin &amp; mv ./nextflow ~/bin/\n</code></pre>"},{"location":"installation/#installation-using-conda","title":"Installation using <code>conda</code>","text":"<p>It is possible to install the basic dependencies using <code>conda</code>,  a package and environment management system. Here, we will use <code>mamba</code>,  which is a reimplementation of the <code>conda</code> package manager in C++  (it has a much faster dependency solver).  </p> <pre><code>mamba install -c bioconda nextflow\n</code></pre> <p>If you do not have <code>conda</code> and <code>mamba</code>, they may be installed running the following commands:  </p> <pre><code>## Install `miniconda`\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh\nbash /tmp/miniconda.sh -b -p $HOME/miniconda\n~/miniconda/bin/conda init bash\nsource ~/.bashrc\nrm /tmp/miniconda.sh\n\n## Install `mamba`\nconda install -c conda-forge mamba\n</code></pre> <p>Conda</p> <p>For more details, see https://docs.conda.io/en/latest/miniconda.html</p>"},{"location":"installation/#container-engines","title":"Container engines","text":"<p>NextITS integrates numerous bioinformatic tools, and managing their installations and updates can be quite intricate for users.  To simplify this, all these tools are packaged within containers.  This not only makes installations hassle-free but also ensures consistent software versions,  guaranteeing reproducible results across different systems.  </p> <p>NextITS supports two container systems:  Singularity and  Docker.  </p> <p>Singularity is often the preferred choice for High-Performance Computing (HPC) environments due to its compatibility and security features.  On the other hand, Docker might be a tad easier to set up on local systems, making it a popular choice for personal use.  </p>"},{"location":"installation/#singularity","title":"Singularity","text":"<p>To install Singularity on Debian-based systems (including Ubuntu), run:</p> <pre><code>## Download dependencies\nsudo apt update &amp;&amp; sudo apt install -y \\\n    build-essential libssl-dev uuid-dev libgpgme11-dev libarchive-dev \\\n    libseccomp-dev wget pkg-config git cryptsetup dh-autoreconf squashfs-tools\n\n## Download GO\nexport VERSION=1.18.1 OS=linux ARCH=amd64 &amp;&amp; \\\n  wget https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz &amp;&amp; \\\n  sudo tar -C /usr/local -xzvf go$VERSION.$OS-$ARCH.tar.gz &amp;&amp; \\\n  rm go$VERSION.$OS-$ARCH.tar.gz\n\necho 'export GOPATH=${HOME}/go' &gt;&gt; ~/.bashrc &amp;&amp; \\\necho 'export PATH=/usr/local/go/bin:$PATH' &gt;&gt; ~/.bashrc &amp;&amp; \\\nsource ~/.bashrc\n\n## Check Go installation\ngo env\n\n## If conda points to wrong locations for Go, reassign environmental variables\nexport GOTOOLDIR=\"/usr/local/go/pkg/tool/linux_amd64\"\nexport GOROOT=\"/usr/local/go\"\n\n## Download singularity\nexport VERSION=3.9.8 &amp;&amp; \\\n  wget https://github.com/sylabs/singularity/releases/download/v${VERSION}/singularity-ce-${VERSION}.tar.gz &amp;&amp; \\\n  tar -xzf singularity-ce-${VERSION}.tar.gz &amp;&amp; \\\n  cd singularity-ce-${VERSION}\n\n## Compile and install Singularity\n./mconfig &amp;&amp; \\\n  make -C builddir &amp;&amp; \\\n  sudo make -C builddir install\n</code></pre> <p>Singularity on HPC clusters</p> <p>If you are working on an HPC cluster, your IT team probably installed Singularity as a Linux Environment Module. You may check Singularity availability using <code>module avail singularity</code> If it is present on your system, you will need to load the module prior to running NextITS. E.g., <code>module load singularityce/3.9.1</code> </p>"},{"location":"installation/#docker","title":"Docker","text":"<p>To install Docker on Ubuntu, run the following commands. For more details, see the Docker installation instructions.  </p> <pre><code>sudo apt-get install \\\n    apt-transport-https \\\n    ca-certificates \\\n    curl \\\n    gnupg-agent \\\n    software-properties-common\n\n## Add Docker\u2019s official GPG key:\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\n\n## Set up the repository\n# Ubuntu\necho \\\n  \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  \"$(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\")\" stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\nsudo apt update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n\nsudo groupadd docker\nsudo usermod -aG docker $USER\nnewgrp docker   \n</code></pre>"},{"location":"installation/#databases","title":"Databases","text":"<p>For ITS amplicons, you may use the following database for reference-based chimera removal: https://owncloud.ut.ee/owncloud/s/iaQ3i862pjwYgdy. This database originates from the most recent version of UNITE, version 9. </p>"},{"location":"installation/#test","title":"Test","text":""},{"location":"installation/#download-the-pipeline-and-test-it-on-a-minimal-dataset-with-a-single-command","title":"Download the pipeline and test it on a minimal dataset with a single command","text":"<pre><code>nextflow run vmikk/nextits -r main -profile test\n</code></pre>"},{"location":"installation/#containers","title":"Containers","text":""},{"location":"installation/#singularity_1","title":"Singularity","text":""},{"location":"installation/#download-container-from-the-singularity-library","title":"Download container from the Singularity library","text":"<pre><code>singularity pull --arch amd64 library://vmiks/nextits/nextits:0-0-5\n</code></pre>"},{"location":"installation/#build-custom-singularity-image","title":"Build custom Singularity image","text":"<pre><code>git clone https://github.com/vmikk/NextITS\nsudo singularity build NextITS.sif ./NextITS/containerfiles/main_container.def\n</code></pre>"},{"location":"installation/#docker_1","title":"Docker","text":""},{"location":"installation/#download-container-from-docker-hub","title":"Download container from Docker Hub","text":"<pre><code>docker pull vmikk/nextits\n</code></pre>"},{"location":"installation/#build-custom-image","title":"Build custom image","text":"<pre><code>git clone https://github.com/vmikk/NextITS\ndocker build --tag nextits --file NextITS/containerfiles/NextITS.dockerfile .\n</code></pre>"},{"location":"installation/#other-container-engines","title":"Other container engines","text":"<p>Other container engines</p> <p>In the future, we plan to add support for the other container engines   (e.g., <code>Podman</code>, <code>Shifter</code>, or <code>Charliecloud</code>) in NextITS.  </p>"},{"location":"parameters/","title":"Parameters","text":"<p>The NextITS pipeline is made up of multiple connected processes.  Each of these processes is amenable to configuration,  empowering users to tailor not just the process parameters  but also the resources allocated for each one (e.g., the number of CPUs).  When setting the pipeline parameter values, users have two choices:  they can specify them directly from the command line using double dash arguments (for example, <code>--its_region \"full\"</code>)  or opt for a simple parameters file. Utilizing a parameters file is especially advantageous  when dealing with numerous settings, as it offers a cleaner command line interface.  In addition to this, individual processes within the pipeline can be fine-tuned using a dedicated config file.  </p> <p>NextITS boasts a vast array of configurable parameters.  For ease of navigation and understanding, these parameters have been grouped into several categories,  detailed in the sections that follow.  </p>"},{"location":"parameters/#step-1","title":"Step-1","text":""},{"location":"parameters/#required-parameters","title":"Required parameters","text":"Parameter Description <code>--input</code> Path to the input file containing single-end sequences (in FASTQ format) or the directory with pre-demultiplexed files <code>--barcodes</code> Path to the file with barcodes (in FASTA format) used for demultiplexing the input data <code>--outdir</code> Path to the directory where the analysis results will be saved. <p>The pipeline can handle both multiplexed and demultiplexed data inputs:  </p> <p>For multiplexed data: - Use the <code>--input</code> parameter to specify a single FASTQ file (e.g., <code>Run01.fastq.gz</code>); - You must also provide the <code>--barcodes</code> parameter, which should reference a FASTA file. The sequence names in this file should correspond to the sample names.  </p> <p>For pre-demultiplexed data (prepared using external tools): - The <code>--input</code> parameter should direct to a directory containing individual FASTQ files for each sample; - There's no need to provide a barcodes file in this case; - Demultiplexed parameter should be enabled (<code>--demultiplexed true</code>).  </p>"},{"location":"parameters/#demultiplexing","title":"Demultiplexing","text":"Parameter Description Default Value <code>--demultiplexed</code> Whether input is multiplexed (<code>false</code>, single FASTQ file) or pre-demultiplexed (<code>true</code>, multiple FASTQ files) <sup>1</sup> <code>false</code> <code>--lima_minscore</code> Barcode score for demultiplexing <sup>2</sup> 93 <code>--lima_barcodetype</code> Barcoding scheme type (<code>single</code>, <code>dual</code>, <code>dual_symmetric</code>, <code>dual_asymmetric</code>) <sup>3</sup> <code>dual_symmetric</code> <code>--lima_W</code> Window size for barcode lookup 70 <code>--lima_minlen</code> Minimum sequence length after clipping barcodes 40 <p><sup>1</sup>:     By default, NextITS assumes you're providing multiplexed data,      which means a single FASTQ file accompanied by a FASTA file containing barcodes.     If your data is already separated into individual samples      (meaning you have multiple FASTQ files, potentially more than one for each sample),      use the <code>--demultiplexed true</code> option.  </p> <p><sup>2</sup>:     For every barcode, LIMA evaluates a score corresponding to its region.      This score signifies the alignment accuracy between the chosen barcode and sequencing read,      and it's determined using the Smith-Waterman algorithm.      For the HiFi data, adjust the score based on your tolerance for contamination:     a setting of <code>--min-score 80</code> should ensure over 99.99% precision.     If you're working with shorter barcodes, such as 10 base pairs, consider reducing the minimum score for optimal results.     For a more comprehensive information, check out https://lima.how/faq/barcode-score.html.  </p> <p><sup>3</sup>:     Barcodes, which can also be referred to as adaptors, tags, indices, molecular identifiers (MIDs), come in various library designs.      At present, NextITS supports 4 barcoding schemes: dual-barcoding (symmetric, assymetric, or mixture of combinatorial tags) and single-barcoding.      For the dual-barcoding scheme, the amplicon should have the barcode on both ends of the amplicon.      An asymmetric design, where each side of the amplicon has a different barcode pair, is also supported.     For a comprehensive understanding of barcode designs, please visit https://lima.how/barcode-design.html.  </p>"},{"location":"parameters/#quality-filtering","title":"Quality filtering","text":"Parameter Description Default Value <code>--qc_maxee</code> Maximum number of expected errors <sup>1</sup> - <code>--qc_maxeerate</code> Maximum number of expected errors per base 0.01 <code>--qc_maxhomopolymerlen</code> Threshold for a homopolymer region length in a sequence <sup>2</sup> 25 <code>--qc_maxn</code> Discard sequences with more than the specified number of ambiguous nucleotides (N's) 4 <p><sup>1</sup>:     As part of the sequence quality control, it is possible to evaluates sequences based on the      maximum number of expected errors (MaxEE) predicted by Phred scores      (Edgar &amp; Flyvbjerg 2015 DOI:<code>10.1093/bioinformatics/btv401</code>)      and the maximum number of expected errors per base. </p> <p><sup>2</sup>:     The ITS region of many fungal and other eukaryotic taxa could commonly harbour homopolymers exceeding 10 bases      (Tedersoo et al. 2022 DOI:<code>10.1111/mec.16460</code>).  </p>"},{"location":"parameters/#removal-of-multiprimer-artifacts-and-reorienting-of-reads","title":"Removal of multiprimer-artifacts and reorienting of reads","text":"Parameter Description Default Value <code>--primer_forward</code> Sequence of the forward primer <sup>1</sup> TACACACCGCCCGTCG <code>--primer_reverse</code> Sequence of the reverse primer <sup>1</sup> CCTSCSCTTANTDATATGC <code>--primer_mismatches</code> Allowed number of mismatches for primers 2 <code>--primer_foverlap</code> Minimum overlap for the forward primer <sup>2</sup> F primer length - 2 <code>--primer_roverlap</code> Minimum overlap for the reverse primer <sup>2</sup> R primer length - 2 <p>Default Primers: By default, NextITS is configured for the data obtained with universal eukaryote primers: - Forward Primer: <code>ITS9MUNngs</code> with sequence <code>TACACACCGCCCGTCG</code> - Reverse Primer: <code>ITS4ngsUni</code> with sequence <code>CCTSCSCTTANTDATATGC</code> Refer to Tedersoo &amp; Lindahl, 2016 DOI:<code>10.1111/1758-2229.12438</code> for more details on these primers.  </p> <p>Alternative Forward Primer: For specific applications, we also recommend the <code>ITS1catta</code> forward primer (sequence: <code>ACCWGCGGARGGATCATTA</code>).  It's designed to target and exclude plant sequences while avoiding interference from the SSU 3\u2032-end intron. For additional information on this primer, consult Tedersoo &amp; Anslan, 2019 DOI:<code>10.1111/1758-2229.12776</code>.  </p>"},{"location":"parameters/#its-extraction","title":"ITS extraction","text":"Parameter Description Default Value <code>--its_region</code> ITS part selector <sup>2</sup> \"full\" <code>--ITSx_tax</code> Taxonomy profile for ITSx <sup>1</sup> \"all\" <code>--ITSx_evalue</code> E-value cutoff threshold for ITSx 1e-1 <code>--ITSx_partial</code> Keep partial ITS sequences (specify a minimum length cutoff), default = off (0) 0 <p>When performing ITS metabarcoding, it's essential to trim the flanking 18S and 28S rRNA genes.  This is crucial because: - These conserved regions don't offer species-level differentiation. - Random errors in these areas can disrupt sequence clustering. - Chimeric breakpoints, which are common in these regions, are hard to detect in short fragments ranging from 10 to 70 bases. (For details, see Lindahl et al. 2013 DOI:<code>10.1111/nph.12243</code> and  Tedersoo et al. 2022 DOI:<code>10.1111/mec.16460</code>).  </p> <p>To address this, NextITS employs the ITSx program (Bengtsson-Palme et al., 2013 DOI:<code>10.1111/2041-210X.12073</code>). By using the <code>--its_region</code> parameter, users can select the region for subsequent analyses. Supported options include: - full: Represents the full-length ITS - ITS1_5.8S_ITS2: A near-full-length ITS that assembles the sequence from the <code>ITS1</code>, <code>5.8S</code>, and <code>ITS2</code> segments extracted by ITSx.   This option is particularly handy when ITSx struggles to detect the end of the SSU.    (for instance, when using the <code>ITS1catta</code> primer, which is located at the extreme end of the SSU and is not detected by ITSx). - ITS1: Represents the ITS1 region - ITS2: Represents the ITS2 region - SSU: Focuses on the small subunit of rRNA (18S) - LSU: Focuses on the large subunit of rRNA (28S) - none: This option only trims primers without extracting the ITS  </p> <p>At the ITS extraction step of the pipeline, you can define a specific taxonomic group of interest.  ITSx employs hidden Markov models (HMMs) tailored for 20 eukaryotic taxonomic groups.  These models detect patterns in rRNA by recognizing variations commonly observed in multiple sequence alignments.  To select the taxon of interest, use the <code>--ITSx_tax</code> parameter.  You can input either single-character codes (e.g., <code>--ITSx_tax f</code>) or full names (e.g., <code>--ITSx_tax fungi</code>).  For multiple selections, provide a comma-separated string, such as <code>--ITSx_tax amoebozoa,rhizaria</code>.  For mixed-taxon datasets, there's an all-encompassing search option: <code>--ITSx_tax all</code> (which is enabled by default).  A table detailing all supported organism groups is provided below:  </p> Code Full name Alternative name <code>.</code> All all <code>A</code> Alveolata alveolates <code>B</code> Bryophyta mosses <code>C</code> Bacillariophyta diatoms <code>D</code> Amoebozoa <code>E</code> Euglenozoa <code>F</code> Fungi <code>G</code> Chlorophyta green-algae <code>H</code> Rhodophyta red-algae <code>I</code> Phaeophyceae brown-algae <code>L</code> Marchantiophyta liverworts <code>M</code> Metazoa animals <code>O</code> Oomycota oomycetes <code>P</code> Haptophyceae prymnesiophytes <code>Q</code> Raphidophyceae raphidophytes <code>R</code> Rhizaria <code>S</code> Synurophyceae synurids <code>T</code> Tracheophyta higher-plants <code>U</code> Eustigmatophyceae eustigmatophytes <code>X</code> Apusozoa <code>Y</code> Parabasalia parabasalids"},{"location":"parameters/#chimera-identification","title":"Chimera identification","text":"Parameter Description Default Value <code>--chimera_db</code> Database for reference-based chimera removal (UDB) - <code>--chimera_rescueoccurrence</code> Min occurrence of chimeric sequences required to rescue them 2 <code>--chimeranov_abskew</code> <code>abskew</code> parameter for de novo chimera identification 2.0 <code>--chimeranov_dn</code> <code>dn</code> parameter for de novo chimera identification 1.4 <code>--chimeranov_mindiffs</code> <code>mindiffs</code> parameter for de novo chimera identification 3 <code>--chimeranov_mindiv</code> <code>mindiv</code> parameter for de novo chimera identification 0.8 <code>--chimeranov_minh</code> <code>minh</code> parameter for de novo chimera identification 0.28 <code>--chimeranov_xn</code> <code>xn</code> parameter for de novo chimera identification 8.0 <p>NextITS employs a two-pronged strategy to detect chimeras:  </p> <ol> <li> <p>De novo Detection:   This algorithm identifies chimeras without relying on reference data.    To mitigate the risk of false-positive detections, sequences flagged as chimeras by the de novo method are not discarded instantly.    Instead, they're assigned a chimeric score. Filtering based on this score can be conducted in subsequent analysis stages (refer to Step-2 for more details).  </p> </li> <li> <p>Reference-based Detection:   This method leverages a reference database in the UDB format.   An example of such a database is accessible at: https://owncloud.ut.ee/owncloud/s/iaQ3i862pjwYgdy.  </p> </li> </ol> <p>Furthermore, NextITS offers an option to \"rescue\" sequences mistakenly labeled as chimeras. The pipeline checks if these sequences appear in other samples where they are not identified as chimeras.  If a sequence is consistently observed, it's more likely to be a genuine biological sequence.  You can control this functionality using the <code>--chimera_rescueoccurrence</code> parameter.  </p>"},{"location":"parameters/#homopolymer-correction","title":"Homopolymer correction","text":"Parameter Description Default Value <code>--hp</code> Enable or disable homopolymer correction <code>true</code> <code>--hp_similarity</code> Allowed sequence similarity for homopolymer correction 0.999 <code>--hp_iddef</code> Sequence similarity definition for homopolymer correction 2 <p>Although the PacBio HiFi reads are highly accurate, but they sometimes show errors in homopolymeric sites (e.g., <code>AAAAAAA</code> stretches).  These sites are also naturally prevalent in fungal ITS.  Such errors can lead to an inflated number of OTUs, slowing down clustering and reducing its efficiency.  To counteract this, NextITS has a strategy to correct these homopolymer errors.  For each sample, the dominant variant of the homopolymer sequence is retained and used.  </p> <p> </p> Homopolymer correction (n is the number of reads)"},{"location":"parameters/#tag-jump-removal-parameters","title":"Tag-jump Removal Parameters","text":"Parameter Description Default Value <code>--tj_f</code> UNCROSS parameter <code>f</code> for tag-jump filtering 0.01 <code>--tj_p</code> Parameter <code>p</code> for tag-jump filtering 1 <code>--otu_id</code> Sequence similarity for OTU clustering 0.98 <code>--otu_iddef</code> Sequence similarity definition for tag-jump removal step 2 <p>Tag-jumps, sometimes referred to as index-switches or index cross-talk, are significant concerns in high-throughput sequencing (HTS) data  (Tedersoo et al. 2022 DOI:<code>10.1111/mec.16460</code>).  They can cause technical cross-contamination between samples, potentially distorting estimates of microbial community composition.  While careful sample indexing can mitigate this problem, a small percentage (approximately 0.01\u20130.1%) of these errors might persist in the data.  </p> <p>NextITS provides a solution to evaluate index-switches using the  UNCROSS2 algorithm  (Edgar 2018 DOI:<code>10.1101/400762</code>),  which assigns an ad hoc score to measure the likelihood of tag-jump events.  </p>"},{"location":"parameters/#step-2","title":"Step-2","text":""},{"location":"parameters/#required-parameters_1","title":"Required parameters","text":"Parameter Description <code>--data_path</code> Input directory containing the results of Step-1 <code>--outdir</code> Path to the directory where the analysis results will be saved."},{"location":"parameters/#denoising-parameters-optional","title":"Denoising parameters (optional)","text":"Parameter Description Default Value <code>--unoise</code> Perform denoising with UNOISE algorithm <code>false</code> <code>--unoise_alpha</code> <code>Alpha</code> parameter of UNOISE <sup>1</sup> 2.0 <code>--unoise_minsize</code> Minimum sequence abundance <sup>2</sup> 8 <p>The UNOISE algorithm (Edgar, 2016, DOI:<code>10.1101/081257</code>)  focuses on error-correction (or denoising) of amplicon reads.  Essentially, UNOISE operates on the principle that if a sequence with low abundance  closely resembles another sequence with high abundance, the former is probably an error.  This helps differentiate between true biological variation and sequencing errors.  </p> <p><sup>1</sup>:     The <code>--unoise_alpha</code> option sets the alpha parameter, as described in the UNOISE2 paper.      Essentially, this parameter establishes the dissimilarity threshold between frequent and infrequent reads.  </p> <p><sup>2</sup>:     The <code>--unoise_minsize</code> option (which corresponds to the <code>-minsize</code> parameter in USEARCH),      determines the minimum abundance a sequence must have across all samples.      Any sequences with abundances below this threshold will be discarded, as sequences with very low abundances tend to be noisy.  </p> <p>It's important to note that UNOISE was initially designed and optimized for Illumina data.  Because of indel errors stemming from inaccuracies in homopolymeric regions,  UNOISE might not work well with data that hasn't undergone homopolymer correction  (more details at the USEARCH web-site). Therefore, when using UNOISE, ensure you activate both options by setting <code>--unoise true</code> and <code>--hp true</code> together.</p>"},{"location":"parameters/#sequence-clustering","title":"Sequence clustering","text":"Parameter Description Default Value <code>--clustering_method</code> Sequence clustering method \"vsearch\" <p>Supported Methods: - vsearch:   This employs greedy clustering using a fixed sequence similarity threshold with    VSEARCH    (Rognes et al., 2016, DOI:<code>10.7717/peerj.2584</code>); - swarm:   Unlike \"vsearch\", this uses a dynamic sequence similarity threshold for clustering with    SWARM    (Mah\u00e9 et al., 2021, DOI:<code>10.1093/bioinformatics/btab493</code>); - unoise:   This focuses solely on denoising to create zero-radius OTUs (zOTUs)    based on the UNOISE3 algorithm    (Edgar, 2016, DOI:<code>10.1101/081257</code>); - shmatching (currently under development):   This method clusters sequences based on species hypotheses (SH) as detailed in    (K\u00f5ljalg et al., 2013, DOI:<code>10.1111/mec.12481</code>,     Abarenkov et al., 2022, DOI:<code>10.3897/biss.6.93856</code>    );  </p>"},{"location":"parameters/#vsearch-clustering","title":"VSEARCH clustering","text":"Parameter Description Default Value <code>--otu_id</code> Sequence similarity threshold 0.98 <code>--otu_iddef</code> Sequence similarity definition (applied to UNOISE as well) 2 <code>--otu_qmask</code> Method to mask low-complexity sequences (applied to UNOISE as well) \"dust\""},{"location":"parameters/#swarm-clustering","title":"SWARM clustering","text":"Parameter Description Default Value <code>--swarm_d</code> SWARM clustering resolution (<code>d</code>) 1 <code>--swarm_fastidious</code> Link nearby low-abundance swarms (<code>fastidious</code> option) <code>true</code> <code>--swarm_d1boundary</code> Minimal mass of large OTUs (only for <code>fastidious</code> with <code>d</code>=1) 3"},{"location":"parameters/#otu-table-preparation-thresholds-for-singleton-and-de-novo-chimera-removal","title":"OTU table preparation, thresholds for singleton and de novo chimera removal","text":"Parameter Description Default Value <code>--merge_replicates</code> Pool sample replicates (e.g., re-sequenced samples) in the final OTU table <code>false</code> <code>--max_MEEP</code> Maximum allowed number of expected errors per 100 bp 0.5 <code>--max_ChimeraScore</code> Maximum allowed de novo chimera score 0.6 <code>--recover_lowqsingletons</code> Logical, Recover de novo chimeras <sup>1</sup> <code>true</code> <code>--recover_denovochimeras</code> Logical, Recover singletons <sup>2</sup> <code>true</code> <p><sup>1</sup>:     Do-novo chimera recovery:     if a sequence identified as putative chimera was observed in the other samples,      where there is no evidence that it is chimeric, it will be recovered.</p> <p><sup>2</sup>:     Singleton recovery:     if a within-sequencing run singleton sequence with relatively low quality (based on MEEP)      was observed in the other samples, it will be recovered.</p>"},{"location":"parameters/#post-clustering-curation-with-lulu","title":"Post-clustering curation with LULU","text":"Parameter Description Default Value <code>--lulu</code> Run LULU true <code>--lulu_match</code> Minimum similarity threshold 95.0 <code>--lulu_ratio</code> Minimum abundance ratio 1.0 <code>--lulu_ratiotype</code> Abundance ratio type - \"min\" or \"avg\" \"min\" <code>--lulu_relcooc</code> Relative co-occurrence 0.95 <code>--lulu_maxhits</code> Maximum number of hits (0 = unlimited) 0 <p>Please Note: The default value for <code>--lulu_match</code>  in NextITS is set to a 95% similarity threshold.  This differs from the original LULU paper, where the default threshold is 84%.</p>"},{"location":"parameters/#miscellaneous-parameters","title":"Miscellaneous parameters","text":"Parameter Description Default Value <code>--gzip_compression</code> Compression level for GZIP <sup>1</sup> 7 <code>--storagemode</code> Adjusts how files are directed to the results folder <sup>2</sup> \"symlink\" <p><sup>1</sup>:     To save disk space and potentially enhance data reading speed,      NextITS compresses data using gzip.      Adjust the balance between speed and compression ratio with the <code>--gzip_compression</code> parameter.      Where <code>-1</code> is the fastest option (worst compression), and <code>-9</code> is slowest (best compression).  </p> <p><sup>2</sup>:     In the default setup, files are directed to the results folder (<code>--output</code>)      using symbolic links (or symlinks) which help save disk space.      Each symlink points to the actual file located in the process working directory.      This behavior can be modified using the <code>--storagemode</code> parameter.     Refer to the table below for a complete list of available storage mode options.  </p> Storage mode Description <code>symlink</code> Creates a symbolic link to the file <code>copy</code> Copies the file to the target directory <code>move</code> Moves the file to the target directory (not recommended) <code>rellink</code> Creates a relative symbolic link to the file <code>link</code> Creates a hard link to the file"},{"location":"quickstart/","title":"Quick start","text":"<p>Get started quickly with NextITS by following these simple instructions.  </p> <p>The pipeline is divided into two main steps: 1. The first step is executed separately for each sequencing run because it involves the removal of tag-jumps. This step primarily focuses on sequence quality control, ITS extraction, and chimera removal. 2. The second step combines data from various runs, clusters sequences using either vsearch or swarm, and then performs post-clustering curation.  </p>"},{"location":"quickstart/#pull-the-latest-pipeline-version","title":"Pull the latest pipeline version","text":"<pre><code>nextflow pull vmikk/NextITS\n</code></pre>"},{"location":"quickstart/#step-1","title":"Step 1","text":"<p>As a first step, each sequencing run must be processed individually.  </p> <p>DRY principle</p> <p>For clarity, we're providing separate commands below.  Note, however, that this approach doesn't adhere to the DRY (Don't Repeat Yourself) principle and may lead to errors.  To minimize potential errors, you can encapsulate the command within a script or function (for details, see below).</p> <p>Sequencing run #1: <pre><code>nextflow run vmikk/NextITS -r main \\\n  -profile singularity \\\n  -resume \\\n  --input          \"$(pwd)/Run01/Run01.fastq.gz\" \\\n  --barcodes       \"$(pwd)/Run01/Run01_barcodes.fasta\" \\\n  --primer_forward \"GTACACACCGCCCGTCG\" \\\n  --primer_reverse \"CCTSCSCTTANTDATATGC\" \\\n  --outdir         \"Step1_Results/Run01\"\n</code></pre></p> <p>Sequencing run #2: <pre><code>nextflow run vmikk/NextITS -r main \\\n  -profile singularity \\\n  -resume \\\n  --input          \"$(pwd)/Run02/Run02.fastq.gz\" \\\n  --barcodes       \"$(pwd)/Run02/Run02_barcodes.fasta\" \\\n  --primer_forward \"GTACACACCGCCCGTCG\" \\\n  --primer_reverse \"CCTSCSCTTANTDATATGC\" \\\n  --outdir         \"Step1_Results/Run02\"\n</code></pre></p> <p>Sequencing run #3: <pre><code>nextflow run vmikk/NextITS -r main \\\n  -profile singularity \\\n  -resume \\\n  --input          \"$(pwd)/Run03/Run03.fastq.gz\" \\\n  --barcodes       \"$(pwd)/Run03/Run03_barcodes.fasta\" \\\n  --primer_forward \"GTACACACCGCCCGTCG\" \\\n  --primer_reverse \"CCTSCSCTTANTDATATGC\" \\\n  --outdir         \"Step1_Results/Run03\"\n</code></pre></p> <p>Container engines</p> <p>In the provided examples, we've assumed that you're utilizing Singularity as your container engine. However, if you prefer to use Docker, it's a straightforward switch.  Simply modify the setting from <code>-profile singularity</code> to <code>-profile docker</code> in the command.  </p>"},{"location":"quickstart/#step-2","title":"Step 2","text":"<p>Step-2 combines the results from Step-1. Then, we can use a greedy algorithm to cluster the sequences, setting a similarity threshold of 98%.  </p> <pre><code>nextflow run vmikk/NextITS -r main \\\n  -main-script Step2_AggregateRuns.nf \\\n  -resume \\\n  -profile     singularity \\\n  --data_path  \"$(pwd)/Step1_Results/\" \\\n  --outdir     \"Step2_Results\" \\\n  --clustering_method \"vsearch\" \\\n  --otu_id 0.98\n</code></pre> <p>The other options</p> <p>Instead of using greedy clustering, you can opt for SWARM clustering,  which employs a dynamic sequence similarity threshold  that aligns with the natural limits of OTUs. Additionally, before clustering or as an alternative to it,  you can denoise the data using the UNOISE algorithm. For more details, see the <code>Usage instructions</code>.</p>"},{"location":"quickstart/#wrapping-a-command-into-a-script","title":"Wrapping a command into a script","text":"<p>To follow the DRY principle,  it is possible to wrap Step-1 commands into a simple script.</p> <pre><code>## Create the script\ncat &gt; run_Step1.sh &lt;&lt;'EOT'\n#!/bin/bash\n\n  ## Positional arguments to the script:\n  # $1 = name of the directory containing FASTQ files\n\n  echo -e \"\\n\"\n  echo -e \"Input data: \" $1\n  echo -e \"Output: \" Step1_Results/\"$1\"\n  echo -e \"Temporary workdirs: \" Step1_WorkDirs/\"$1\"\n\n  BASEDIR=$(pwd)\n\n  ## Create output directories\n  mkdir -p Step1_Results/\"$1\"\n  mkdir -p Step1_WorkDirs/\"$1\"\n  cd Step1_WorkDirs/\"$1\"\n\n  ## Run Step-1 of the pipeline\n  nextflow run \"$NEXTITS_PATH\"/main.nf \\\n    -resume \\\n    -profile     docker \\\n    --input      \"$BASEDIR\"/Input/\"$1\"/*.fastq.gz \\\n    --barcodes   \"$BASEDIR\"/Input/\"$1\"/*.fasta \\\n    --outdir     \"$BASEDIR\"/Step1_Results/\"$1\" \\\n    -work-dir    \"$BASEDIR\"/Step1_WorkDirs/\"$1\" \\\n    --tracedir   \"$BASEDIR\"/Step1_WorkDirs/\"$1\"/pipeline_info \\\n  | tee Nextflow_\"$1\".log\n\nEOT\n\n## Make the script executable\nchmod +x run_Step1.sh\n</code></pre> <p>The script assumes that the data is structured such that  the <code>Input</code> directory houses multiple sub-directories corresponding to different sequencing runs  (e.g., <code>Run01</code>, <code>Run02</code>, <code>Run03</code>), and within each of these sub-directories,  there two files: a <code>FASTQ</code> file containing high-throughput data and a <code>FASTA</code> file with barcodes. For example:  </p> <pre><code>Input/\n\u251c\u2500\u2500 Run01/\n\u2502   \u251c\u2500\u2500 Run01.fastq.gz\n\u2502   \u2514\u2500\u2500 Run01_barcodes.fasta\n\u251c\u2500\u2500 Run02/\n\u2502   \u251c\u2500\u2500 Run02.fastq.gz\n\u2502   \u2514\u2500\u2500 Run02_barcodes.fasta\n\u2514\u2500\u2500 Run03/\n    \u251c\u2500\u2500 Run03.fastq.gz\n    \u2514\u2500\u2500 Run03_barcodes.fasta\n</code></pre> <p>To initiate the analysis for individual sequencing runs, execute the following commands: <pre><code>./run_Step1.sh \"Run01\"\n./run_Step1.sh \"Run02\"\n./run_Step1.sh \"Run03\"\n</code></pre></p> <p>If you have a large number of sequencing runs,  you can automate the process by combining the <code>find</code> and  GNU <code>parallel</code>  utilities: <pre><code>find $(pwd)/Input/ -type d -not -path $(pwd)/Input/ \\\n  | sort \\\n  | parallel -j1 \"./run_Step1.sh {/}\"\n</code></pre> This command will locate all sub-directories within the <code>Input</code> directory and run the analysis script for each one.</p>"},{"location":"quickstart/#configuring-the-pipeline","title":"Configuring the pipeline","text":"<p>While we have endeavored to choose the most sensible default options for the NextITS pipeline,  it's worth noting that there are numerous parameters available for configuration and fine-tuning,  allowing users to adapt the pipeline to best fit their data.  </p> <p>Detailed descriptions of these parameters can be found in the <code>Parameters</code> section of the documentation.</p>"},{"location":"usage/","title":"NextITS pipeline usage examples","text":""},{"location":"usage/#quick-start","title":"Quick Start","text":"<pre><code>nextflow run vmikk/NextITS -r main \\\n  -profile singularity \\\n  -resume \\\n  --input          \"pacbio_ccs.fastq.gz\" \\\n  --barcodes       \"sample_barcodes.fasta\" \\\n  --primer_forward \"GTACACACCGCCCGTCG\" \\\n  --primer_reverse \"CCTSCSCTTANTDATATGC\" \\\n  --its_region     \"full\" \\\n  --blast_taxdb    \"false\" \\\n  --outdir         \"Results\"\n</code></pre>"},{"location":"usage/#input-data","title":"Input data","text":""},{"location":"usage/#sequences","title":"Sequences","text":"<p>For PacBio data, NextITS requires a single FASTQ file (<code>--input</code> argument) with multiplexed samples.  </p>"},{"location":"usage/#barcodes","title":"Barcodes","text":"<p>For demultiplexing, sample barcodes (a.k.a. tags or indices) should be provided in a FASTA file  and have the following format: <pre><code>&gt;RunID__Sample_01\nACAACACTCCGA\n&gt;RunID__Sample2\nACAAGTGCTGCT\n&gt;RunID__PosC\nACACAGTCCTGA\n</code></pre></p> <p>In NextITS, we use the <code>SequencingRunID__SampleID</code> naming convention  (please note the double underscore separating <code>RunID</code> and <code>SampleID</code> parts).  This naming scheme allows to easily trace back sequences, especially if the same sample  was sequenced several times and is present in multiple sequencing runs.  In the later steps, extracting the <code>SampleID</code> part and summarizing read counts for such samples is easy.  </p> <p>Sample naming</p> <p>Please avoid non-ASCII symbols in <code>RunID</code> and <code>SampleID</code>, and do not use the period symbol (<code>.</code>), as it represents the wildcard character in regular expressions. Also, it is preferable not to start the sample name with a number.  </p> <p>Demultiplexing of PacBio data is performed using <code>lima</code> software.  To identify best-matching barcodes, lima computes the alignment score of each barcode.  These scores depend on the barcode length.  In NextITS, the default threshold for the minimum accepted score is provided with the expectation that barcodes have a length of 12 bp.  If your barcodes are shorter or you use barcodes of different lengths, you may need to adjust the <code>--lima_minscore</code> parameter.  </p> <p>Depending on the DNA library design, your amplicon sequences could be tagged with barcodes in different ways. NextITS supports multiple multiplexing strategies that can be specified with the <code>--lima_barcodetype</code> parameter:</p> <ul> <li><code>dual_symmetric</code> - identical barcodes at both ends (default)</li> <li><code>dual_asymmetric</code> - different barcodes at 5' and 3' ends</li> <li><code>dual</code> - a mixture of symmetric and asymmetric barcodes</li> <li><code>single</code> - barcodes only at one end</li> </ul> <p>For dual-barcoding schemes, provide barcode pairs in the FASTA file using the following format:</p> <pre><code>&gt;RunID__Sample_01\nACAACACTCCGA...TGCTAGCTAGCT\n&gt;RunID__Sample2\nACAAGTGCTGCT...GCATGCATGCAT\n</code></pre> <p>Unique barcodes</p> <p>Make sure that the provided sample names and barcode sequences (or barcode combinations) are unique!</p>"}]}